# DrugsLM

[![CCDS](https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter)](https://cookiecutter-data-science.drivendata.org/)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](LICENSE)

## Small Language Model (SLM) for Pharmaceutical Information

Master's thesis in Computer Science at the Federal University of ParanÃ¡ (UFPR), focusing on the development of a specialized language model using drug package inserts and medical databases.

---

## ğŸ¯ Overview

DrugsLM is a research project that aims to create a domain-specific language model trained on pharmaceutical data from regulatory agencies. Unlike general-purpose LLMs, DrugsLM focuses on:

- **Accuracy**: Training exclusively on verified sources (ANVISA, FDA, medical literature)
- **Multilingual**: Primary focus on Portuguese with English expansion
- **Efficiency**: Small Language Model design for reduced computational requirements
- **Traceability**: Complete data lineage from source to model

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker & Docker Compose** (recommended)
- **Python 3.12** with [uv](https://github.com/astral-sh/uv) package manager
- **Selenium Hub** (for web scraping) - optional, configurable via `HUB_URL`

### Installation

#### Option 1: Using Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/drugslm.git
cd drugslm

# Start services
docker compose up -d drugslm  # Base container
docker compose up -d mkdocs   # Documentation server (localhost:8000)
docker compose up -d dagster  # Orchestration UI (localhost:3000)

# Attach to container
docker exec -it drugslm_base bash
```

#### Option 2: Local Development

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Setup development environment
make install  # Install uv (if not already installed)
make dev      # Create venv and install all dependencies

# Activate environment
source .venv/bin/activate

# Or use uv directly (no activation needed)
uv run python -m drugslm.scraper.anvisa.catalog --help
```

### Running Your First Scraper

```bash
# Fetch metadata from ANVISA categories
uv run python -m drugslm.scraper.anvisa.catalog run --fetch-only

# Run full scraping pipeline (single-threaded)
uv run python -m drugslm.scraper.anvisa.catalog run

# Parallel execution with 4 threads
uv run python -m drugslm.scraper.anvisa.catalog run --threads 4

# Check data consistency
uv run python -m drugslm.scraper.anvisa.catalog run --check
```

---

## ğŸ“ Project Structure

```
drugslm/
â”œâ”€â”€ dagster/                   # Orchestration layer (mirrors drugslm/)
â”‚   â”œâ”€â”€ scraper/              # Dagster assets for data acquisition
â”‚   â””â”€â”€ modeling/             # Dagster pipelines for training
â”‚
â”œâ”€â”€ drugslm/                   # Core Python package
â”‚   â”œâ”€â”€ scraper/              # Data acquisition modules
â”‚   â”‚   â”œâ”€â”€ anvisa/           # ANVISA scraper (active)
â”‚   â”‚   â”‚   â”œâ”€â”€ catalog.py    # Drug listing scraper
â”‚   â”‚   â”‚   â”œâ”€â”€ leaflets.py   # PDF download module
â”‚   â”‚   â”‚   â”œâ”€â”€ pipelines.py  # Dagster integration
â”‚   â”‚   â”‚   â””â”€â”€ config.py     # ANVISA-specific config
â”‚   â”‚   â”œâ”€â”€ wikipedia/        # Wikipedia scraper (planned)
â”‚   â”‚   â””â”€â”€ selenium.py       # Shared browser automation
â”‚   â”‚
â”‚   â”œâ”€â”€ modeling/             # Model training and evaluation
â”‚   â”œâ”€â”€ features/             # Feature engineering
â”‚   â”œâ”€â”€ database/             # Database connectors
â”‚   â”‚   â”œâ”€â”€ pg/              # PostgreSQL
â”‚   â”‚   â””â”€â”€ neo4j/           # Neo4j graph database
â”‚   â”œâ”€â”€ utils/               # Shared utilities
â”‚   â”‚   â”œâ”€â”€ logging.py       # Logging configuration
â”‚   â”‚   â””â”€â”€ asserts.py       # Validation helpers
â”‚   â””â”€â”€ config.py            # Global configuration
â”‚
â”œâ”€â”€ data/                      # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                  # Immutable source data
â”‚   â”‚   â””â”€â”€ anvisa/          # ANVISA scraped data
â”‚   â”‚       â””â”€â”€ index/       # Drug catalog and metadata
â”‚   â”œâ”€â”€ interim/             # Intermediate transformed data
â”‚   â”œâ”€â”€ processed/           # Final analysis-ready datasets
â”‚   â””â”€â”€ external/            # Third-party data sources
â”‚
â”œâ”€â”€ models/                    # Trained models and artifacts
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for exploration
â”œâ”€â”€ docs/                      # MkDocs documentation source
â”œâ”€â”€ tests/                     # Pytest test suite
â”‚
â”œâ”€â”€ docker-compose.yaml        # Multi-service orchestration
â”œâ”€â”€ Dockerfile                 # Development container definition
â”œâ”€â”€ Makefile                   # Development shortcuts
â”œâ”€â”€ pyproject.toml            # Python package configuration
â””â”€â”€ mkdocs.yaml               # Documentation configuration
```

### Key Directories

- **`drugslm/scraper/`**: Modular scrapers for each data source (ANVISA, Wikipedia, etc.)
- **`dagster/`**: Dagster assets and pipelines that mirror the `drugslm/` structure
- **`data/raw/anvisa/index/`**: Scraped catalog stored as pickle/CSV with checkpointing
- **`docs/`**: Full documentation built with MkDocs Material

---

## ğŸ› ï¸ Development Workflow

### Common Commands

```bash
# Environment Management
make dev          # Setup full dev environment
make build        # Production build (main dependencies only)
make clean        # Remove Python artifacts and caches
make purge        # Nuclear option: remove venv + artifacts

# Code Quality
make lint         # Check code style with ruff
make format       # Auto-format code with ruff
make test         # Run pytest suite

# Services
make dagster up   # Start Dagster dev server (0.0.0.0:3000)
make docs up      # Serve documentation with live reload (0.0.0.0:8000)
make dagster down # Stop Dagster
make docs down    # Stop MkDocs
```

### Documentation

Access full documentation at `http://localhost:8000` when running `make docs up`, or visit the ~~online docs~~ (TODO: add GitHub Pages link).

---

## ğŸ—ï¸ Architecture Overview

The project follows a modular data pipeline architecture:

```mermaid
flowchart LR
    A[Data Sources] --> B[Scrapers]
    B --> C[Raw Storage]
    C --> D[Processing]
    D --> E[Feature Engineering]
    E --> F[Model Training]
    F --> G[Deployment]
    
    style B fill:#ffc107
    style F fill:#dc3545
```

**Current Focus**: Data acquisition layer (scrapers) and raw data validation.

For detailed architecture decisions, see [Architecture Documentation](architecture.md).

---

## ğŸ“Š Data Sources

### Active

- **ANVISA** (Brazilian Health Regulatory Agency)
- ~40,000+ registered medications
- Official package inserts (PDF)
- Regulatory metadata

### Planned

- **Wikipedia** (Multilingual drug information)
- **PubMed/Medical Literature**

---

## ğŸ¤ Contributing

This is an active research project. Contributions, suggestions, and feedback are welcome:

1. Open an issue for bugs or feature requests
2. Fork the repository for pull requests
3. Follow existing code style (enforced by `ruff`)

---

## ğŸ“ Citation

If you use this work in your research, please cite:

```bibtex
@mastersthesis{goncalves2025drugslm,
  author  = {GonÃ§alves, VinÃ­cius de Lima},
  title   = {DrugsLM: A Small Language Model for Pharmaceutical Information},
  school  = {Federal University of ParanÃ¡},
  year    = {2025},
  type    = {Master's Thesis},
  address = {Curitiba, Brazil}
}
```

---

## ğŸ“„ License

This project is licensed under the BSD 3-Clause License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**VinÃ­cius de Lima GonÃ§alves**  
Master's Student in Computer Science  
Federal University of ParanÃ¡ (UFPR)  
Curitiba, Brazil

---

**Documentation**: [Getting Started](getting-started.md) | [Architecture](architecture.md) | [API Reference](reference/)
